%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%  Template for homework of Introduction to Machine Learning.
%
%  Fill in your name, lecture number, lecture date and body
%  of homework as indicated below.
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\documentclass[11pt,letter,notitlepage]{article}
%Mise en page
\usepackage[left=2cm, right=2cm, lines=45, top=0.8in, bottom=0.7in]{geometry}
\usepackage{fancyhdr}
\usepackage{fancybox}
\usepackage{graphicx}
\usepackage{pdfpages} 
\usepackage{enumitem}
\usepackage[UTF8]{ctex}
\renewcommand{\headrulewidth}{1.5pt}
\renewcommand{\footrulewidth}{1.5pt}
\pagestyle{fancy}
\newcommand\Loadedframemethod{TikZ}
\usepackage[framemethod=\Loadedframemethod]{mdframed}

\usepackage{amssymb,amsmath}
\usepackage{amsthm}
\usepackage{thmtools}

\setlength{\topmargin}{0pt}
\setlength{\textheight}{9in}
\setlength{\headheight}{0pt}

\setlength{\oddsidemargin}{0.25in}
\setlength{\textwidth}{6in}

%%%%%%%%%%%%%%%%%%%%%%%%
%% Define the Exercise environment %%
%%%%%%%%%%%%%%%%%%%%%%%%
\mdtheorem[
topline=false,
rightline=false,
leftline=false,
bottomline=false,
leftmargin=-10,
rightmargin=-10
]{exercise}{\textbf{Exercise}}
%%%%%%%%%%%%%%%%%%%%%%%
%% End of the Exercise environment %%
%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%
%% Define the Solution Environment %%
%%%%%%%%%%%%%%%%%%%%%%%
\declaretheoremstyle
[
spaceabove=0pt, 
spacebelow=0pt, 
headfont=\normalfont\bfseries,
notefont=\mdseries, 
notebraces={(}{)}, 
headpunct={:\quad}, 
headindent={},
postheadspace={ }, 
postheadspace=4pt, 
bodyfont=\normalfont, 
qed=$\blacksquare$,
preheadhook={\begin{mdframed}[style=myframedstyle]},
	postfoothook=\end{mdframed},
]{mystyle}

\declaretheorem[style=mystyle,title=Solution,numbered=no]{solution}
\mdfdefinestyle{myframedstyle}{%
	topline=false,
	rightline=false,
	leftline=false,
	bottomline=false,
	skipabove=-6ex,
	leftmargin=-10,
	rightmargin=-10}
%%%%%%%%%%%%%%%%%%%%%%%
%% End of the Solution environment %%
%%%%%%%%%%%%%%%%%%%%%%%

%% Homework info.
\newcommand{\posted}{\text{Oct. 05, 2019}}       			%%% FILL IN POST DATE HERE
\newcommand{\due}{\text{Oct. 12, 2019}} 			%%% FILL IN Due DATE HERE
\newcommand{\hwno}{\text{2}} 		           			%%% FILL IN LECTURE NUMBER HERE


%%%%%%%%%%%%%%%%%%%%
%% Put your information here %%
%%%%%%%%%%%%%%%%%%%
\newcommand{\name}{\text{Bowen Zhang}}  	          			%%% FILL IN YOUR NAME HERE
\newcommand{\id}{\text{PB17000215}}		       			%%% FILL IN YOUR ID HERE
%%%%%%%%%%%%%%%%%%%%
%% End of the student's info %%
%%%%%%%%%%%%%%%%%%%


\newcommand{\proj}[2]{\textbf{P}_{#2} (#1)}
\newcommand{\lspan}[1]{\textbf{span}  (#1)  }
\newcommand{\rank}[1]{ \textbf{rank}  (#1)  }
\newcommand{\dom}{ \textbf{dom}  }
\newcommand{\RNum}[1]{\uppercase\expandafter{\romannumeral #1\relax}}


\lhead{
	\textbf{\name}
}
\rhead{
	\textbf{\id}
}
\chead{\textbf{
		Homework \hwno
}}


\begin{document}
\vspace*{-4\baselineskip}
\thispagestyle{empty}


\begin{center}
{\bf\large Introduction to Machine Learning}\\
{Fall 2019}\\
University of Science and Technology of China
\end{center}

\noindent
Lecturer: Jie Wang  			 %%% FILL IN LECTURER HERE
\hfill
Homework \hwno             			
\\
Posted: \posted
\hfill
Due: \due
\\
Name: \name             			
\hfill
ID: \id						
\hfill

\noindent
\rule{\textwidth}{2pt}

\medskip





%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% BODY OF HOMEWORK GOES HERE
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\textbf{Notice, }to get the full credits, please present your solutions step by step.

\begin{exercise}[Lipschitz Continuity \textnormal{10pts}]
Suppose that $f:\mathbb{R}^n\rightarrow\mathbb{R}$ is twice continuously differentiable, and the gradient of $f$ is Lipschitz continuous, i.e.,
\begin{align*}
    \|\nabla f(x)-\nabla f(y)\|_2\le L\|x-y\|_2, \forall\,x,y\in\mathbb{R}^n,
\end{align*}
where $L>0$ is the Lipschitz constant. Please find the relation between $L$ and the largest eigenvalue of $\nabla^2 f(x)$.
\end{exercise}
\begin{solution}
    \heiti \ \\
    构造函数 $g(t)= \nabla f(x+c t y),$\  $\forall\,x,y\in\mathbb{R}^n,$，其中 $c$ 是常数。\\
    那么存在 $\xi \subset (0,1)$ ，使得：\\
    $\begin{array}{l}{\qquad \begin{aligned}  \nabla f(x+c y)-\nabla f(x) &=g(1)-g(0) \\ &=g^{\prime}\left(\xi \right)(1-0) \\ &=\nabla^{2} f(x+c\xi y)c y \end{aligned}} \\  \end{array}$\\
    两边同时取模得：\\
    $ \Rightarrow \left\|\nabla^{2} f(x+c \xi y) c y\right\|_2 =\|\nabla f(x+c y)-\nabla f(x)\|_2$\\
    由题目条件得：\\
    ${\Rightarrow\left\|\nabla^{2} f(x+c \xi y) y\right\|_2 \leqslant L\|y\|_2}$\\
    令 ${c \rightarrow 0}$ 得：\\
    ${\Rightarrow\left\|\nabla^{2} f(x) y\right\|_2 \leqslant L\|y\|_2}$\\
    由于对 $\nabla^{2}f(x) $ 的最大特征值 $\lambda_{max}$ 和对应的特征向量 $y_m$ 有：$ \nabla^{2}f(x)y_m = \lambda_{max} y_m$，
    综上说明对 $\nabla^{2}f(x)$ 的最大特征值小于等于 $L$.
\end{solution}
\newpage



\begin{exercise}[Gradient Descent for Convex Optimization Problems \textnormal{20pts}]
    Consider the following problem 
\begin{align}\label{prob:c_min}
    \min_{x}f(x),
\end{align}
where $f$ is convex and its gradient is Lipschitz continuous with constant $L>0$. Assume that $f$ can attain its minimum.
\begin{enumerate}
    \item Show that the optimal set $\mathcal{C}=\{y:f(y)=\min_{x}f(x)\}$ is convex.
    \item Suppose that $d(x,\mathcal{C})=\inf_{z\in\mathcal{C}}\|x-z\|_2$. Consider the problem (\ref{prob:c_min}) and the sequence generated by the gradient descent algorithm. Show that $d(x_k,\mathcal{C})\rightarrow 0$ as $k\rightarrow\infty$. 
\end{enumerate}
\end{exercise}
\begin{solution}
    \ \\
    \heiti
    \begin{enumerate}
        \item \ \\
        取 $y_1, y_2 \in \mathcal{C}$，满足
        \begin{align*}
            f(y_1) = \min_{x}f(x);\\
            f(y_2) = \min_{x}f(x).
        \end{align*}
        考察 $\theta y_1 + (1-\theta) y_2$，由 $f(x)$ 是凸函数可知：
        \begin{align*}
            f(\theta y_1+(1-\theta) y_2) &\leq \theta f(y_1) + (1 - \theta) f(y_2) \\
            & = \min_{x}f(x)
        \end{align*}
        由上可知 $\mathcal{C}$ 是凸集。
    \item \ \\
        取 $x^* \in \mathcal{C}$，考察:\\
        $\begin{aligned} &\left\|x_{k+1}-x^*\right\|^{2}-\left\|x_{k}-x^*\right\|^{2}-\left\|x_{k+1}-x_{k}\right\|^{2} \\=&-2 x^*\left(x_{k+1}-x_{k}\right)-2 x_{k}\left(x_{k}-x_{k+1}\right) \\=&-2\left(x^*-x_{k}\right)\left(x_{k+1}-x_{k}\right) \\=& 2 \alpha<\nabla f\left(x_{k}\right), x^*-x_{k}>\end{aligned}$ \\
        其中，用到了 $x_{k+1} = x_k - \alpha \nabla f(x_k)$ . \\
        结合 $f(x)$ 为凸函数的一阶性质：\\
        \begin{align*}
            f(x^*) \geqslant f\left(x_{k}\right)+\left\langle\nabla f\left(x_{k}\right), x^*-x_{k}\right\rangle
        \end{align*}
        $\Rightarrow$ 原式
        $\leq 2 \alpha\left(f(z)-f\left(x_{k}\right)\right)$
        $\leqslant 0$.\\
        课上已经求得：
        \begin{align*}
            \sum\limits_{i=1}^{\infty} \| x_{i+1} - x_{i} \| ^2 \leq \frac{2L}{2-L\alpha} \| f(x_0) - f^*\|^2   \dots (1)
        \end{align*}
        现在取 ${x_k}$ 的一个趋向 $z$ 子列，其中 $z \in \mathcal{C}$，记为${x_{l_k}}$。任取$\delta > 0$，那么必定存在 $l_{k_0}$ 使得 $\| x_{l_{k_0}} - z \|^2 \leq \frac{\delta}{2}$，根据 (1) 存在 $l_{k_1}$ 使得 $\sum\limits_{i=l_{k_1}}^{\infty} \| x_{i+1} - x_{i} \| ^2 \leq \frac{\delta}{2}$. 那么对于 $k > max(k_0, k_1)$ \\
        $\begin{aligned}\left\|x_{k}-z\right\|^{2} & \leqslant\left\|x_{l_k}-z\right\|^{2}+\sum_{j=l_k}^{k-1}\left\|x_{j+1}-x_{j}\right\|^{2} \\ & \leqslant \frac{\delta}{2}+\sum_{j=l_k}^{\infty}\left\|x_{j+1}-x_{j}\right\|^{2} \\ & \leqslant \frac{\delta}{2}+\frac{\delta}{2}=\delta \end{aligned}$.\\
        令 $k\rightarrow\infty, \delta \rightarrow 0$ 即得 $x_k$ 收敛于$z$，而 $z \in \mathcal{C}$，所以 $d(x_k,\mathcal{C})\rightarrow 0$.
    \end{enumerate}
\end{solution}
\newpage



\begin{exercise}[Gradient Descent for Strongly Convex Optimization Problems \textnormal{50pts}]
A function $f$ is strongly convex with parameter $\mu$ if $f(x)-\frac{\mu}{2}\|x\|_2^2$ is convex.
\begin{enumerate}
    \item Show that a continuously differentiable function $f$ is strongly convex if and only if 
    \begin{align*}
        f(y)\ge f(x)+\langle\nabla f(x),y-x\rangle+\frac{\mu}{2}\|y-x\|_2^2, \forall\, x,y\in\mathbb{R}^n
    \end{align*}
    \item Suppose that $f$ is twice differentiable. Please find the relation between $\mu$ and the smallest eigenvalue of $\nabla^2f(x)$.
\end{enumerate}

\noindent Consider the following problem 
\begin{align}\label{prob:sc_min}
    \min_{x}f(x),
\end{align}
where $f$ is strongly convex with convexity parameter $\mu>0$ and its gradient is Lipschitz continuous with constant $L>0$.
\begin{enumerate}[resume]
    \item Show that the problem (\ref{prob:sc_min}) admits a unique solution.
    \item Show that
    \begin{align*}
        f(y)\ge f(x)-\frac{1}{2\mu}\|\nabla f(x)\|_2^2, \forall\, x,y.
    \end{align*}
    \item Consider the problem (\ref{prob:sc_min}) and the sequence generated by the gradient descent algorithm. Suppose that $x^*$ is the solution to the problem \ref{prob:sc_min}. Show that
    \begin{align*}
        f(x_k)-f(x^*)\le (1-\mu\alpha(2-L\alpha))^k(f(x_0)-f(x^*)).
    \end{align*}
    Find the range of $\alpha$ such that the function values $f(x_k)$ converge linearly to  $f(x^*)$.
\end{enumerate}
\end{exercise}
\begin{solution}
    \heiti
    \ \\
    \begin{enumerate}
        \item \ \\
        "$\Rightarrow$"\\
        由已知可得 $f(x)-\frac{\mu}{2}\|x\|_{2}^{2}$ 是凸函数，那么对$ \forall\, x,y\in\mathbb{R}^n $，由凸函数的一阶性质有：\ \\
        $\begin{array}{l}{\left. f(y)-\frac{\mu}{2}\|y\|_{2}^{2} \geqslant f(x)-\frac{\mu}{2}\|x\|_{2}^{2}+\langle \nabla (f(x)-\frac{\mu}{2}\|x\|_{2}^{2}\right), y-x\rangle} \\ {\Rightarrow f(y) \geqslant f(x)+\frac{\mu}{2}\left(\|y\|_{2}^{2}-\|x\|_{2}^{2}\right)+\langle\nabla f(x)-\mu x, y-x\rangle} \\ {\Rightarrow f(y) \geqslant f(x)+\langle\nabla f(x), y-x\rangle+\frac{\mu}{2}\left(\|y\|_{2}^{2}+\|x\|_{2}^{2} - \|x\|_{2}\left\|y\right\|_{2}\right)} \\ {\Rightarrow f(y) \geqslant f(x)+\langle \nabla f(x), y-x \rangle+\frac{\mu}{2} \| y - x \|_{2}^{2}}\end{array}$\\ \ \\
        "$\Leftarrow$"\\
        由已知，对$ \forall\, x,y\in\mathbb{R}^n $可得：\\
        $\begin{aligned} & f(y) \geqslant f(x)+\langle\nabla f(x), y-x\rangle+\frac{\mu}{2}\|y-x\|_{2}^{2} \\ \Rightarrow & f(y) \geqslant f(x)+\langle\nabla f(x), y-x\rangle+\frac{\mu}{2}\|y\|_{2}^{2}-\mu\|y\|_{2}\|x\|_{2}+\frac{\mu}{2}\|x\|_{2}^{2} \\ \Rightarrow & f(y)-\frac{\mu}{2}\|y\|_{2}^{2} \geqslant f(x)-\frac{\mu}{2}\|x\|_{2}^{2}+\langle\nabla f(x), y-x\rangle+\langle{-\mu x} , y-x\rangle\\ \Rightarrow &\left.f(y)-\frac{\mu}{2}\|y\|_{2}^{2} \geqslant f(x)-\frac{\mu}{2}\|x\|_{2}^{2}+\langle\nabla (f(x)-\frac{\mu}{2}\|x\|_{2}^{2}\right), y-x\rangle\end{aligned}$\\ \ \\
        而这说明 $f(x)-\frac{\mu}{2}\|x\|_2^2$ 是凸函数。
        \item \ \\
        取 $\forall\, x,y\in\mathbb{R}^n$ 有：\\
        $\begin{array}{l}{f(y) \geq f(x)+\langle\nabla f(x), y-x\rangle+\frac{\mu}{2}\|y-x\|_{2}^{2} \ldots (1)} \\ {f(x) \geq f(y)+\langle\nabla f(y), x-y\rangle+\frac{\mu}{2}\|x-y\|_{2}^{2} \cdots (2)} \\ {(1)+(2) \Rightarrow} \\ {\langle\nabla f(x)-\nabla f(y), x-y\rangle \geqslant \mu\|x-y\|_{2}^{2} \ldots (3)}\end{array}$\\ \ \\
        构造函数 $g(t)= \nabla f(x+c t y)$，其中 $c$ 是常数。\\
        那么存在 $\xi \subset (0,1)$ ，使得：\\
        $\begin{array}{l}{\qquad \begin{aligned}  \nabla f(x+c y)-\nabla f(x) &=g(1)-g(0) \\ &=g^{\prime}\left(\xi \right)(1-0) \\ &=\nabla^{2} f(x+c\xi y)c y \ldots (4)\end{aligned}} \\  \end{array}$\\
        根据(3)有:
        \begin{align*}
            \langle\nabla f(x + cy)-\nabla f(x), cy\rangle \geqslant \mu\|cy\|_{2}^{2} \ldots (5)
        \end{align*}
        (4)代入(5)，两边同时取模得：\\
        $ \left\|\nabla^{2} f(x+c \xi y) \|y\|_{2}^{2}\right\|_2 \geq \mu \| \|y \|_{2}^{2} \|_2$\\
        令 $c \rightarrow 0$ 可得：\\
        $ \left\|\nabla^{2} f(x) \|y\|_{2}^{2}\right\|_2 \geq \mu\|y\|_{2}^{2}$\\
        这说明对 $\nabla^{2}f(x)$ 的任何特征值的绝对值都大于等于 $\mu$，所以其最小特征值的绝对值也大于等于 $\mu$.
        \item \ \\
        假设存在$x_1, x_2$ 满足:\\
        \begin{align*}
            f(x_1) = f(x_2) = \min_{x}f(x)
        \end{align*}
        由 2. 中的式 (3) 可知:\\
        \begin{align*}
            \langle\nabla f(x_1)-\nabla f(x_2), x_1-x_2\rangle \geqslant \mu\|x_1-x_2\|_{2}^{2}
        \end{align*}
        由于都到达了最小值，所以$\nabla f(x_1) = \nabla f(x_2) = 0$，所以有：\\
        \begin{align*}
            \|x_1-x_2\|_{2}^{2} \leq 0\\
            \Rightarrow x_1 = x_2
        \end{align*}
        由此可知只有唯一解。
        \item \ \\由已知条件：\\
        $ \begin{aligned} f(y) & \geqslant f(x)+\langle\nabla f(x), y-x\rangle+\frac{\mu}{2}\|y-x\|_{2}^{2} \\ \Rightarrow f(y) & \geqslant f(x) - \langle\nabla f(x), x-y\rangle+\frac{\mu}{2}\|y-x\|_{2}^{2} \\ & \geqslant f(x)-\|\nabla f(x)\|_{2}\|x-y\|+\frac{\mu}{2}\|x - y\|_{2}^{2}  \end{aligned} $\\
        令 $t = \|x - y \|$，不等式右侧看作关于 $t$ 的二次函数，在 $t= \frac{\|\nabla f(x)\|}{2 \cdot \frac{\mu}{2}}$ 时取得最小值，于是：\\
        \begin{align*}
            f(y) &\geqslant f(x)-\|\nabla f(x)\|_{2} \frac{\|\nabla f(x)\|_{2}}{\mu}+\frac{\mu}{2} \frac{\|\nabla f(x)\|^{2}}{\mu^{2}}
        \end{align*}
        于是有：\\
        \begin{align*}
            f(y) \geqslant f(x)-\frac{1}{2 \mu}\|\nabla f(x)\|_{2}^{2}
        \end{align*}
        \item \ \\
        由 4. 可得：\\
        $\begin{aligned} f\left(x^{*}\right) & \geqslant f\left(x_{x}\right)-\frac{1}{2 \mu}\left\|\nabla f\left(x_{k}\right)\right\|_{2}^{2} \\ \Rightarrow\left\|\nabla f\left(x_{x}\right)\right\|_{2}^{2} & \geqslant -2 \mu\left(f\left(x^{*}\right)-f\left(x_{k}\right)\right) \cdots (1)  \end{aligned}$\\ \ \\
        由课上所讲的引理（从函数梯度是 Lipschitz 连续可推）有：
        \begin{align*}
            f\left(x_{k+1}\right) \leqslant f\left(x_{k}\right)-\alpha\left(1-\frac{L \alpha}{2}\right)\left\|\nabla f\left(x_{k}\right)\right\|_{2}^{2}
        \end{align*}
        将(1)代入：
        \begin{align*}
           f(x_{k+1}) & \leqslant f\left(x_{k}\right)+2 \mu \alpha \left(1-\frac{L \alpha}{2}\right)\left(f\left(x_{k}\right)-f\left(x^{*}\right)\right) \\ &=\left(1-\mu \alpha (2-L \alpha )) f\left(x_{k}\right)+\mu \alpha (2-L \alpha) f\left(x^{*}\right)\right.\\
           f\left(x_{k+1}\right)-f\left(x^{*}\right) & \leqslant\left(1-\mu \alpha(2-L \alpha )\right)\left(f\left(x_{k}\right)-f\left(x^{*}\right)\right)
        \end{align*}
        不等式两边同时求和并变换下标得：
        \begin{align*}
            f\left(x_{k}\right)-f\left(x^{*}\right) & \leqslant(1-\mu \alpha(2-L\alpha ))^{k}\left(f\left(x_{0}\right)-f\left(x^{*}\right)\right)
        \end{align*}
        \item \ \\
        由于要保证收敛，所以将 $x_{k+1} = x_{k} - \alpha \nabla f(x_k)$ 代入 1. 中的不等式得
        \begin{align*}
        \begin{array}{c}{f\left(x_{k+1}\right) \geqslant f\left(x_{k}\right)+\langle \nabla f\left(x_{k}\right), x_{k+1}-x_{k}\rangle+\frac{\mu}{2} \| x_{k+1} -x_k }\|_2^2 \\ {f\left(x_{k+1}\right) \geqslant f\left(x_{k}\right)+\left(\frac{\mu}{2} \alpha^{2}-\alpha\right)\left\|\nabla f\left(x_{k}\right)\right\|_{2}^{2}}\\{0\geqslant f\left(x_{k+1}\right) - f(x_k) \geqslant \left(\frac{\mu}{2} \alpha^{2}-\alpha\right)\left\|\nabla f\left(x_{k}\right)\right\|_{2}^{2}} \\ {\frac{\mu}{2} \alpha^{2}-\alpha \leqslant 0} \\ {\alpha \leqslant \frac{2}{\mu}}\end{array}
        \end{align*}
        根据线性收敛的定义，存在实数$0 < q < 1$，使得$\lim _{k \rightarrow \infty} \frac{\left\|f(x_{k+1})-f(x^{*})\right\|}{\left\|f(x_{k})-f(x^{*})\right\|}=q$ 则当：\\
        \begin{align*} 
            0<\frac{f\left(x_{k+1}\right)-f\left(x^{*}\right)}{f\left(x_{k}\right)-f\left(x^{*}\right)} \leqslant 1-\mu \alpha(2-L \alpha) < 1
        \end{align*}
        可以保证线性收敛。
        \begin{align*}
            0 < 1-\mu \alpha(2-L \alpha) < 1
        \end{align*}
        右侧不等式解得：
        \begin{align*}
            &\alpha(2-L \alpha) < 1 \\ \Rightarrow & 0<\alpha<\frac{2}{L}
        \end{align*}
        左侧不等式对应的二次函数恒大于0，故不等式自然成立。\\
        由 exercise1 和 2. 可知 $L \geqslant |\lambda_{max} | \geqslant |\lambda_{min} | \geqslant \mu$，故综上可得：
        \begin{align*}
            0<\alpha<\frac{2}{L}
        \end{align*}
        时，可以保证线性收敛。
    \end{enumerate}

\end{solution}
\newpage



\begin{exercise}[Programming Exercise \textnormal{20pts}]
    We provide you with a data set, where the number of samples $n$ is $16087$ and the number of features $d$ is $10013$. Suppose that $\textbf{X}\in\mathbb{R}^{n\times d}$ is the input feature matrix and $\textbf{y}\in\mathbb{R}^n$ is the corresponding response vector. We use the linear model to fit the data, and thus we can formulate the optimization problem as 
    \begin{align}\label{prob:lsm}
        \arg\min_{\textbf{w}} \frac{1}{n}\|\textbf{y}-\bar{\textbf{X}}\textbf{w}\|_2^2,
    \end{align}
    where $\bar{\textbf{X}}=(\textbf{1},\textbf{X})\in\mathbb{R}^{n\times(d+1)}$ and $\textbf{w}=(w_0,w_1,\dots,w_n)^\top\in\mathbb{R}^{d+1}$.
    Finish the following exercises by programming. You can use your favorite programming language.
    \begin{enumerate}
        \item Normalize the columns $\textbf{x}_i$ of $\bar{\textbf{X}}$ ($2\le i\le d+1$) as follows:
        \begin{align*}
            \textbf{x}_{ij}\leftarrow\frac{\textbf{x}_{ij}-\min (\textbf{x}_i)}{\max (\textbf{x}_i)-\min (\textbf{x}_i)},
        \end{align*}
        where $\textbf{x}_{ij}$ denote thes $j$th entry of $\textbf{x}_i$. Use the normalized $\bar{\textbf{X}}$ in the following exercises.
        \item Use the closed form solution to solve the problem (\ref{prob:lsm}), and get the solution $\textbf{w}_0^*$.
        \item Use the gradient descent algorithm to solve the problem (\ref{prob:lsm}). Stop the iteration until $|f(\textbf{w}_k)-f(\textbf{w}_0^*)|<0.1$, where $f(\textbf{w}) = \frac{1}{n}\|\textbf{y}-\bar{\textbf{X}}\textbf{w} \|_2^2$. Plot $f(\textbf{w}_k)$ versus the iteration step $k$. 
    \end{enumerate}
    Compare the time cost of the two approaches in 2 and 3.
    
\end{exercise}
\begin{solution}
    \heiti
    \ \\
    第二问和第三问的代码分别附在 $prob4\_2.m$ 和 $prob4\_3.m$ 中，数据归一化操作在每段代码开始计算之前进行。\\
    运行环境：128 G 内存，64核 Intel(R) Xeon(R) Platinum 8153 CPU @ 2.00GHz\\
    用时：\\闭式解方法：35.072 s \\
    梯度下降法(学习率 0.6)：1min 53.533 s\\ 
    梯度下降文件中将残差保存在 $cost\_history.txt$ 文件中，使用 $plot.py$ 进行画图，保存为$Cost-Iteration step.png$。
\end{solution}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\end{document}
